{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88221d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scans/FLD_1_cut.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/FLD_2_cut.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/FLD_3_cut.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/FLD_10_cut.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/FLD_11_cut.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/FLD_12_cut.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/TGA_1_cut.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/TGA_4_cut.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_F1_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_F2_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_F3_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_CF1_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_CF2_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_CF3_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_C1_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_C2_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_C3_BC.mhd loaded (100, 100, 100) \n",
      "\n",
      "CPU times: user 1min 47s, sys: 9.33 s, total: 1min 57s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "# Importing Packages\n",
    "import os\n",
    "from PIL import Image\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import glob\n",
    "from skimage import transform\n",
    "from sys import getsizeof\n",
    "\n",
    "from functions_cnn import *\n",
    "\n",
    "# Loading Images\n",
    "newImageResolution = 100\n",
    "FLD1  = makeCubeArray('Scans/FLD_1_cut.mhd', newImageResolution, adjustScans=True)\n",
    "FLD2  = makeCubeArray('Scans/FLD_2_cut.mhd', newImageResolution, adjustScans=True)\n",
    "FLD3  = makeCubeArray('Scans/FLD_3_cut.mhd', newImageResolution, adjustScans=True)\n",
    "FLD10 = makeCubeArray('Scans/FLD_10_cut.mhd', newImageResolution, adjustScans=True)\n",
    "FLD11 = makeCubeArray('Scans/FLD_11_cut.mhd', newImageResolution, adjustScans=True)\n",
    "FLD12 = makeCubeArray('Scans/FLD_12_cut.mhd', newImageResolution, adjustScans=True)\n",
    "F1 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_F1_BC.mhd', newImageResolution, adjustScans=True)\n",
    "F2 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_F2_BC.mhd', newImageResolution, adjustScans=True)\n",
    "F3 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_F3_BC.mhd', newImageResolution, adjustScans=True)\n",
    "CF1 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_CF1_BC.mhd', newImageResolution, adjustScans=True)\n",
    "CF2 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_CF2_BC.mhd', newImageResolution, adjustScans=True)\n",
    "CF3 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_CF3_BC.mhd', newImageResolution, adjustScans=True)\n",
    "C1 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_C1_BC.mhd', newImageResolution, adjustScans=True)\n",
    "C2 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_C2_BC.mhd', newImageResolution, adjustScans=True)\n",
    "C3 = makeCubeArray('Scans/041022_Blarr_CF_20-47_FLD_C-F_3_F_1-3-0123,00_recon_C3_BC.mhd', newImageResolution, adjustScans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1aca953",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Bit array size:  112000.16  KB\n",
      "16 Bit array size:  28000.16  KB \n",
      "\n",
      "Data Shape before Augemntation: (14, 100, 100, 100)\n",
      "(28, 100, 100, 100)\n",
      "(42, 100, 100, 100)\n",
      "(56, 100, 100, 100)\n",
      "(112, 100, 100, 100)\n",
      "(224, 100, 100, 100)\n",
      "(448, 100, 100, 100)\n",
      "Data Shape after Augemntation: (448, 100, 100, 100) \n",
      "\n",
      "The FibrePerc list was multiplied 32.0 times \n",
      "\n",
      "split:  299 / 149\n"
     ]
    }
   ],
   "source": [
    "# Gathering Images in a dictionary\n",
    "# The values represent the FVCs that were determined experimentally\n",
    "Data = {'FLD1':0.223, \n",
    "        'FLD2':0.255, \n",
    "        'FLD3':0.286, \n",
    "        #'FLD10':0.179, #This scan caused unexplained abnormalities and is thus removed\n",
    "        'FLD11':0.240, \n",
    "        'FLD12':0.266,\n",
    "        'F1':0.230669,\n",
    "        'F2':0.220811,\n",
    "        'F3':0.230589,\n",
    "        'CF1':0.255740,\n",
    "        'CF2':0.223137,\n",
    "        'CF3':0.228111,\n",
    "        'C1':0.263567,\n",
    "        'C2':0.231027,\n",
    "        'C3':0.238066,\n",
    "}\n",
    "\n",
    "keys = [*Data.keys()] #Contains all Fibre Percentages\n",
    "n0 = len(keys) #Initial amount of scans used\n",
    "\n",
    "# Making array containing the 3D-arrays of all scans\n",
    "Scans_float64 = np.array([globals()[keys[i]] for i in range(n0)])\n",
    "print(\"64 Bit array size: \", getsizeof(Scans_float64)/1000, \" KB\")\n",
    "\n",
    "# Reducing all values to 16 bits (equivalent to the maximum original information content of each CT scan)\n",
    "Scans_float16 = np.array([np.float16(Scans_float64[i]) for i in range(n0)])\n",
    "print(\"16 Bit array size: \", getsizeof(Scans_float16)/1000, \" KB\", \"\\n\")\n",
    "Scans = Scans_float16 #For simplicity, the variable name is adjusted\n",
    "\n",
    "# Augmentation\n",
    "print(\"Data Shape before Augemntation:\", Scans.shape)\n",
    "#Defining vectors for the geometrical operations\n",
    "direct_x = 0\n",
    "direct_y = 1\n",
    "direct_z = 2\n",
    "normalPlane_x = (1,2)\n",
    "normalPlane_y = (2,0)\n",
    "normalPlane_z = (0,1)\n",
    "#Expanding the Scan set with augmented versions\n",
    "#Both size inputs are identical to create cuboid-shaped arrays to allow for more augmentation steps \n",
    "Scans = addRotations(Scans, normalPlane_x, n0, newImageResolution, newImageResolution) #Adding 90° x-rotated scans to \"Scans\" array\n",
    "Scans = addRotations(Scans, normalPlane_y, n0, newImageResolution, newImageResolution) #Adding 90° y-rotated scans to \"Scans\" array\n",
    "Scans = addRotations(Scans, normalPlane_z, n0, newImageResolution, newImageResolution) #Adding 90° z-rotated scans to \"Scans\" array\n",
    "Scans = addFlips(Scans, direct_x, newImageResolution, newImageResolution) #Adding x-flipped scants to \"Scans\" array\n",
    "Scans = addFlips(Scans, direct_y, newImageResolution, newImageResolution) #Adding y-flipped scants to \"Scans\" array\n",
    "Scans = addFlips(Scans, direct_z, newImageResolution, newImageResolution) #Adding z-flipped scants to \"Scans\" array\n",
    "print(\"Data Shape after Augemntation:\", Scans.shape, \"\\n\")\n",
    "\n",
    "# Creating the fiber precentages list\n",
    "FibrePerc = np.array([*Data.values()])\n",
    "fvc_appended = FibrePerc\n",
    "for i in range(int(Scans.shape[0] / n0) - 1): # Mulitplying the Fibre Precentage list\n",
    "    fvc_appended = np.append(fvc_appended, FibrePerc)\n",
    "FibrePerc = fvc_appended\n",
    "print(\"The FibrePerc list was multiplied\", Scans.shape[0] / n0, \"times\", \"\\n\")\n",
    "\n",
    "# Defining the Split between input and validation Data\n",
    "split_border = 2/3\n",
    "split = round(len(Scans) * split_border) #Using 1/3 of Data for validation\n",
    "print(\"split: \", split, \"/\", len(Scans)-split)\n",
    "\n",
    "inputScans = Scans[:split] #Split for training data\n",
    "InputScans = tf.expand_dims(inputScans, axis = 4)\n",
    "inputLabels = FibrePerc[:split]\n",
    "\n",
    "testScans = Scans[split:] #Split for validation data\n",
    "TestScans = tf.expand_dims(testScans, axis = 4)\n",
    "testLabels = FibrePerc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e33bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final CNN\n",
    "\n",
    "def get_model(depth, width, height):\n",
    "    inputs = keras.Input((depth, width, height, 1))\n",
    "    \n",
    "    x = tf.keras.layers.Normalization(axis=-1, invert=True)\n",
    "\n",
    "    x = layers.Conv3D(filters=2, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling3D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Dense(units=64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    \n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs, name=\"3dcnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97fc0ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 100, 1  0         \n",
      "                             )]                                  \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 98, 98, 98, 2)     56        \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 49, 49, 49, 2)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 49, 49, 49, 64)    192       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 49, 49, 49, 64)    0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 49, 49, 49, 128)   8320      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 49, 49, 49, 128)   0         \n",
      "                                                                 \n",
      " global_average_pooling3d_1   (None, 128)              0         \n",
      " (GlobalAveragePooling3D)                                        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,697\n",
      "Trainable params: 8,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " 1/10 [==>...........................] - ETA: 26s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/phkunze/Library/Mobile Documents/com~apple~CloudDocs/IAM Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     ,optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mlr_schedule)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     ,metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Initial prediction (without training)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m y_m1 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(InputScans)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m y_m1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maround(y_m1, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mflatten() \u001b[39m#reshape data for better visualisaition\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m deviation(inputLabels, y_m1)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2350\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2348\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2349\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2350\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   2351\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2352\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training and prediction\n",
    "\n",
    "#Defining adjustable learning rate\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "model = get_model(depth=newImageResolution, width=newImageResolution, height=newImageResolution) #Selecting the network architecture\n",
    "model.summary() #prints out the overview over the network structure\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\"\n",
    "    ,optimizer=keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    ,metrics=['mae']\n",
    ")\n",
    "\n",
    "# Initial prediction (without training)\n",
    "y_m1 = model.predict(InputScans)\n",
    "y_m1 = np.around(y_m1, 3).flatten() #reshape data for better visualisaition\n",
    "deviation(inputLabels, y_m1)\n",
    "\n",
    "# Train model\n",
    "epochs = 40\n",
    "hist = model.fit(Scans, FibrePerc, epochs = epochs, validation_split = 1 - split_border, shuffle = True)\n",
    "\n",
    "# New prediction (after training)\n",
    "y_m2 = model.predict(InputScans)\n",
    "y_m2 = np.around(y_m2, 3).flatten() #reshape data for better visualisaition\n",
    "deviation(inputLabels, y_m2)\n",
    "\n",
    "# Predicting validation data\n",
    "y_m3 = model.predict(TestScans)\n",
    "y_m3 = np.around(y_m3, 3).flatten() #reshape data for better visualisaition\n",
    "print(\"Result from test data prediction:\")\n",
    "deviation(testLabels, y_m3)\n",
    "\n",
    "# Loss Plot\n",
    "import matplotlib\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=250)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('loss_normal_network_without_normalization.eps', format='eps')\n",
    "plt.savefig('loss_normal_network_without_normalization.png', dpi=250, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "#Plotting results for the validation Data\n",
    "X_test = np.arange(len(Scans)-split)\n",
    "fig = plt.figure(figsize=(10, 6), dpi=250)\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(X_test + 0.00, testLabels, color = 'tab:red', width = 0.15)\n",
    "ax.bar(X_test + 0.25, y_m3, color = 'green', width = 0.15)\n",
    "ax.set_ylabel('Vol. fibre percentage')\n",
    "ax.set_xlabel('testScans')\n",
    "ax.legend(labels=['testLabels', 'prediction'])\n",
    "plt.savefig('results_normal_network_without_normalization.eps', format='eps')\n",
    "plt.savefig('results_normal_network_without_normalization.png', dpi=250, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "305402ff-1ba1-4afd-af9a-d450a00e07ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.230669 0.220811 0.230589 0.25574  0.223137 0.228111 0.263567 0.231027\n",
      " 0.238066 0.223    0.255    0.286    0.24     0.266    0.230669 0.220811\n",
      " 0.230589 0.25574  0.223137 0.228111 0.263567 0.231027 0.238066 0.223\n",
      " 0.255    0.286    0.24     0.266    0.230669 0.220811 0.230589 0.25574\n",
      " 0.223137 0.228111 0.263567 0.231027 0.238066 0.223    0.255    0.286\n",
      " 0.24     0.266    0.230669 0.220811 0.230589 0.25574  0.223137 0.228111\n",
      " 0.263567 0.231027 0.238066 0.223    0.255    0.286    0.24     0.266\n",
      " 0.230669 0.220811 0.230589 0.25574  0.223137 0.228111 0.263567 0.231027\n",
      " 0.238066 0.223    0.255    0.286    0.24     0.266    0.230669 0.220811\n",
      " 0.230589 0.25574  0.223137 0.228111 0.263567 0.231027 0.238066 0.223\n",
      " 0.255    0.286    0.24     0.266    0.230669 0.220811 0.230589 0.25574\n",
      " 0.223137 0.228111 0.263567 0.231027 0.238066 0.223    0.255    0.286\n",
      " 0.24     0.266    0.230669 0.220811 0.230589 0.25574  0.223137 0.228111\n",
      " 0.263567 0.231027 0.238066 0.223    0.255    0.286    0.24     0.266\n",
      " 0.230669 0.220811 0.230589 0.25574  0.223137 0.228111 0.263567 0.231027\n",
      " 0.238066 0.223    0.255    0.286    0.24     0.266    0.230669 0.220811\n",
      " 0.230589 0.25574  0.223137 0.228111 0.263567 0.231027 0.238066 0.223\n",
      " 0.255    0.286    0.24     0.266    0.230669 0.220811 0.230589 0.25574\n",
      " 0.223137 0.228111 0.263567 0.231027 0.238066] [0.23  0.226 0.222 0.229 0.221 0.226 0.217 0.246 0.224 0.258 0.285 0.282\n",
      " 0.251 0.255 0.23  0.226 0.222 0.229 0.221 0.226 0.217 0.246 0.224 0.258\n",
      " 0.285 0.283 0.251 0.254 0.23  0.226 0.223 0.229 0.222 0.226 0.217 0.246\n",
      " 0.225 0.259 0.285 0.283 0.251 0.255 0.231 0.226 0.222 0.229 0.222 0.226\n",
      " 0.218 0.246 0.224 0.259 0.285 0.283 0.251 0.254 0.23  0.226 0.222 0.229\n",
      " 0.221 0.226 0.217 0.245 0.224 0.258 0.285 0.282 0.251 0.254 0.23  0.226\n",
      " 0.222 0.229 0.221 0.226 0.217 0.246 0.224 0.258 0.285 0.283 0.251 0.255\n",
      " 0.231 0.226 0.222 0.229 0.222 0.226 0.218 0.246 0.225 0.259 0.285 0.283\n",
      " 0.251 0.255 0.23  0.226 0.222 0.229 0.221 0.226 0.218 0.246 0.225 0.259\n",
      " 0.285 0.283 0.251 0.255 0.23  0.226 0.222 0.229 0.221 0.225 0.217 0.246\n",
      " 0.224 0.259 0.285 0.282 0.25  0.254 0.23  0.226 0.223 0.229 0.221 0.226\n",
      " 0.217 0.246 0.225 0.258 0.285 0.283 0.251 0.255 0.23  0.226 0.223 0.229\n",
      " 0.222 0.226 0.217 0.246 0.225]\n"
     ]
    }
   ],
   "source": [
    "# Saving values as .csv file to plot figure 30\n",
    "np.savetxt(\"results_normal_network_deviation_without_normalization.csv\", np.column_stack((testLabels, y_m3)), delimiter=\",\", header=\"original, predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f17bf076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_filters:  2 |  n_layers:   1 |  dropout:   0 |  kernel:   1 |  pool:   2\n",
      "Iteration:  1 / 1500\n",
      "10/10 [==============================] - 4s 434ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/phkunze/Library/Mobile Documents/com~apple~CloudDocs/IAM Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#X24sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Train Model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#X24sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#X24sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(Scans, FibrePerc, epochs \u001b[39m=\u001b[39;49m epochs, validation_split \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m split_border, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#X24sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# New Prediction (after training)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phkunze/Library/Mobile%20Documents/com~apple~CloudDocs/IAM%20Arbeit/FVC_NN/cnn_fvc/CT_Analysis_CNN_cubes_final.ipynb#X24sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m y_m2 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(InputScans)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1681\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1682\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1693\u001b[0m     )\n\u001b[0;32m-> 1694\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1695\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1696\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1697\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1698\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1699\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1700\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1701\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1702\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1703\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1704\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1705\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1706\u001b[0m )\n\u001b[1;32m   1707\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1708\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1709\u001b[0m }\n\u001b[1;32m   1710\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2037\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2038\u001b[0m ):\n\u001b[1;32m   2039\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2040\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   2041\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2042\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optional parameter sweep to optimize the network\n",
    "\n",
    "\"\"\" \n",
    "def get_model_parametrized(depth, width, height, n_filters, n_layers, dropout, kernel, pool):\n",
    "    inputs = keras.Input((depth, width, height, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=n_filters, kernel_size=kernel, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling3D(pool_size=pool)(x)\n",
    "    \n",
    "    for layer in range(1, n_layers+1):\n",
    "        x = layers.Dense(units=8*2**layer, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    \n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "\n",
    "\n",
    "# Defining which and how many veriables are used for the sweep\n",
    "# For actual sweep executions, a smaller set was used to avoid having to do 1500 iterations in one run\n",
    "filters_list = [2, 4, 8, 16, 32]\n",
    "layers_list = [1, 2, 3, 4, 5]\n",
    "dropout_list = [0, 0.1, 0.3, 0.5, 0.8]\n",
    "kernel_list = [1, 3, 5, 7]\n",
    "pool_list = [2, 3, 4]\n",
    "\n",
    "n_Iterations = len(filters_list)*len(layers_list)*len(dropout_list)*len(kernel_list)*len(pool_list)\n",
    "results = np.zeros((n_Iterations, 8))\n",
    "\n",
    "sweepCounter = 0\n",
    "for n_filters in filters_list:\n",
    "    for n_layers in layers_list:\n",
    "        for dropout in dropout_list:\n",
    "            for kernel in kernel_list:\n",
    "                for pool in pool_list:\n",
    "                    print(\"n_filters: \", n_filters, \"| \", \"n_layers:  \", n_layers, \"| \", \"dropout:  \", dropout, \"| \", \"kernel:  \", kernel, \"| \", \"pool:  \", pool)\n",
    "                    print(\"Iteration: \", sweepCounter+1, \"/\", n_Iterations)\n",
    "\n",
    "                    # Training Setup\n",
    "\n",
    "                    initial_learning_rate = 0.0001\n",
    "                    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True) # Defining adjustable learning rate\n",
    "    \n",
    "                    model = get_model_parametrized(depth=newImageResolution, width=newImageResolution, height=newImageResolution, n_filters=n_filters, n_layers = n_layers, dropout=dropout, kernel=kernel, pool=pool)\n",
    "                    model.compile(\n",
    "                        loss=\"binary_crossentropy\"\n",
    "                        ,optimizer=keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "                        ,metrics=['mae']\n",
    "                    )\n",
    "\n",
    "                    # Initial Prediction (without training)\n",
    "                    y_m1 = model.predict(InputScans)\n",
    "\n",
    "                    # Train Model\n",
    "                    epochs = 40\n",
    "                    hist = model.fit(Scans, FibrePerc, epochs = epochs, validation_split = 1 - split_border, verbose=0)\n",
    "\n",
    "                    # New Prediction (after training)\n",
    "                    y_m2 = model.predict(InputScans)\n",
    "                    \n",
    "                    # Predicting validation data\n",
    "                    y_m3 = model.predict(TestScans)\n",
    "                    print(\"Result from test data prediction:\")\n",
    "                    deviation(testLabels, y_m3)\n",
    "\n",
    "                    #Saving Data\n",
    "                    results[sweepCounter][0] = getSAD()\n",
    "                    results[sweepCounter][1] = getSAD_rel()\n",
    "                    results[sweepCounter][2] = n_filters\n",
    "                    results[sweepCounter][3] = n_layers\n",
    "                    results[sweepCounter][4] = dropout\n",
    "                    results[sweepCounter][5] = kernel\n",
    "                    results[sweepCounter][6] = pool\n",
    "                    sweepCounter += 1\n",
    "\n",
    "np.savetxt(\"results.csv\", results, delimiter=\",\", header=\"SAD, SAD relative, n_filters, n_layers, dropout, n_kernels, pool\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowTest",
   "language": "python",
   "name": "tensorflowtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
